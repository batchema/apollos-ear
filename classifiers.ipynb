{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio Classifier for Apollo's Ear",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Apollo's Ear Classifiers: Classify audio accross 13 genres\n",
        "\n",
        "We will implement a set of 3 audio classification networks supporting eleven different major musical genres.\n",
        "\n",
        "*   Target Accuracy - 80%\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## System setup\n",
        "\n",
        "- Mount Google Drive\n",
        "- Set Tensorflow version to 2.x\n",
        "- Enable GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m5f0TVgL_GY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3540ac2d-d5a6-4c55-b336-02a441880f19"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXnDmXR7RDr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78de956c-957f-47a5-fa06-209ac0583c26"
      },
      "source": [
        "# Set up Tensorflow 2.x\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26v7Kg6VxBAg"
      },
      "source": [
        "# Data Aggregation\n",
        "The following are utilities functions for aggregating, cleaning, and formatting audio for analysis. Note that Using Selenium does not work with Google Collab. I performed the data aggregation on my laptop\n",
        "\n",
        "##Note on the Dataset\n",
        "The famous [GTZAN](https://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification?) Dataset contains data for blues, classical, country, hiphop, jazz, metal, pop, reggae, rock. Coming from Africa however, I need to be able to classify [Afrobeat]('https://en.wikipedia.org/wiki/Afrobeats'), [Coupe Decale]('https://en.wikipedia.org/wiki/Coup%C3%A9-d%C3%A9cal%C3%A9') (which is my favorite music genre), and [Rumba]('https://en.wikipedia.org/wiki/Rumba') (the favorite of my parents). \n",
        "To extend the data, I relied on [selenium]('https://selenium-python.readthedocs.io/')and on [pytubeX]('https://pypi.org/project/pytubeX/'), a youtube stream download package. First, I found some youtube playlists that I thought were representative enough of the 3 genres. This is not scientifically rigorous, but given that the playlists were at least amont the top three popular ones when I looked for the genre names, this is not too bad. Then, I used Selenium to extract video URLS which I then tested, (again using Selenium) to makes sure that the videos were live. Next, I used the pytube to get the audio of the videos. Finally, I used FFMPEG to splice 30 random seconds from each audio file which I then discarded. I believe scientific exploration is fair use under copyright law, but better be safe than sorry.\n",
        "See [audio_data_collectors.py]() for the utility functions if you need to gather extra data. Else, you can just use the excellent [GTZAN](https://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification?) dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGFf7bPsuBfQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "# Music Data Preparation\n",
        "The following are a set of utility functions for features extraction from audio data.  Follow the steps after gathering all the needed data.\n",
        "\n",
        "##Note on the features\n",
        "We will be using two different types of classifiers. The first one will be [Multilayer perceptron (MLP)](https://en.wikipedia.org/wiki/Multilayer_perceptron), the second one a [Convolutional Neural Network (CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network), and the third is [Recurrent Neural Network with Longterm Shorterm Memory (RNN-LSTM)](https://people.cs.pitt.edu/~jlee/papers/cs3750_rnn_lstm_slides.pdf). \n",
        "For the MLP we will be using a large set of features: [spectral bandwidth](https://www.timbercon.com/resources/glossary/spectral-bandwidth/), [spectral rollof](https://www.mathworks.com/help/audio/ref/spectralrolloffpoint.html), [spectral chromagram](https://en.wikipedia.org/wiki/Chroma_feature), [zero crossing rates](https://en.wikipedia.org/wiki/Zero-crossing_rate), [tempogram](https://musicinformationretrieval.com/tempo_estimation.html), and the means of [Mel-Frequency Cepstral coefficients (MFCCs)](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum). For the CNN, we will only use the logs of the [Mel Spectrograms](https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53). Finally for the RNN, we will use the MFCCs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U18oz5-nbDB1"
      },
      "source": [
        "# modules imports\n",
        "import math\n",
        "import librosa # library for extracting audio data features\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQi1spviQLVR"
      },
      "source": [
        "# The structure of the extraction functions was inspired by \n",
        "# https://github.com/musikalkemist/DeepLearningForAudioWithPython/blob/master/12-%20Music%20genre%20classification:%20Preparing%20the%20dataset/code/extract_data.py\n",
        "\n",
        "# Define constants so that we do not always need to pass in function paramaters\n",
        "WORKING_FOLDER = \"/content/drive/My Drive/Apollo's Ear\"\n",
        "DATA_PATH = f\"{WORKING_FOLDER}/data/genres\"\n",
        "TEST_DATA_PATH = f\"{WORKING_FOLDER}/test\"\n",
        "MLP_FEATURES = f\"{WORKING_FOLDER}/data/mlp_features.csv\"\n",
        "RNN_FEATURES = f\"{WORKING_FOLDER}/data/rnn_features.json\"\n",
        "CNN_FEATURES = f\"{WORKING_FOLDER}/data/cnn_features.json\" \n",
        "GENRE_NAMES = {\"afrobeat\", \"blues\",\"classical\", \"country\",\"coupe_decale\", \\\n",
        "               \"disco\",\"hiphop\", \"jazz\",\"metal\", \"pop\", \"reggae\", \"rock\",\"rumba\"}\n",
        "SAMPLE_RATE = 22050 # sample rate often used in audio classification\n",
        "TRACK_DURATION = 30 #seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "\n",
        "def extract_features_MLP(data_path=DATA_PATH, output_path=MLP_FEATURES,\n",
        "                      num_mfcc=13, num_fft=2048, hop_length=512, num_segments=5):\n",
        "  \"\"\"Extracts and puts into csv format music features to be used for the MLP classifier\n",
        "    :param data_path (str): Path to audio data\n",
        "    :param output_path (str): Path for json output\n",
        "    :param coef_num (str): Number of mfcc coefficients\n",
        "    :param ftt_num_sample (str): NUmber of fast fourier transform samples\n",
        "    :param data_path (str): Path to audio data\n",
        "    :return None\n",
        "  \"\"\"\n",
        "# Prepare data storage\n",
        "  output = open(output_path, 'w', newline='')\n",
        "  header = 'filename spectral_centroid spectral_bandwidth spectral_rolloff chroma_stft zero_crossing_rate tempogram '\n",
        "  for i in range(num_mfcc):\n",
        "    header += f' mfcc{i}'\n",
        "  header += ' label'\n",
        "  header = header.split();\n",
        "  with output:\n",
        "    writer = csv.writer(output)\n",
        "    writer.writerow(header)\n",
        "\n",
        "  # Extract and store features \n",
        "  samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "  num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        "\n",
        "  for i, (dirpath, dirnames, filenames) in enumerate(os.walk(data_path)):\n",
        "    \n",
        "    # process every folder in data_path directory\n",
        "    if dirpath is not data_path and os.path.isdir(dirpath):\n",
        "\n",
        "      #Save genre label in data[\"mapping\"]\n",
        "      genre_label = dirpath.split(\"/\")[-1]\n",
        "      \n",
        "      #Process every audio file in genre folder\n",
        "      for filename in filenames:\n",
        "        file_path = os.path.join(dirpath, filename)\n",
        "        signal, sample_rate = None, None\n",
        "        try:\n",
        "          signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "        except:\n",
        "          print(filename, 'start-finish:', start, '-', finish)\n",
        "          continue\n",
        "\n",
        "        # Process every audio segment in audio file\n",
        "        for s in range(num_segments):\n",
        "          try:\n",
        "            start = samples_per_segment * s\n",
        "            finish = start + samples_per_segment\n",
        "                      \n",
        "            #Extract spectral centroid\n",
        "            spec_cent = librosa.feature.spectral_centroid(y=signal[start:finish],\\\n",
        "                          sr=sample_rate, n_fft=num_fft, hop_length=hop_length)                \n",
        "            # #Extract spectral bandwidth\n",
        "            spec_bw = librosa.feature.spectral_bandwidth(y=signal[start:finish],\\\n",
        "                          sr=sample_rate, n_fft=num_fft, hop_length=hop_length)\n",
        "            \n",
        "            # Extract spectral rolloff\n",
        "            spec_ro = librosa.feature.spectral_rolloff(y=signal[start:finish],\\\n",
        "                          sr=sample_rate, hop_length=hop_length)\n",
        "            \n",
        "            # Extract chromagram\n",
        "            chroma_stft = librosa.feature.chroma_stft(y=signal[start:finish],\\\n",
        "                          sr=sample_rate, hop_length=hop_length)\n",
        "            \n",
        "            #Extract zero crossing rate\n",
        "            zcr = librosa.feature.zero_crossing_rate(y=signal[start:finish],\\\n",
        "                          hop_length=hop_length)\n",
        "            \n",
        "            #Extract tempogram\n",
        "            tpg = librosa.feature.tempogram(y=signal[start:finish],\\\n",
        "                          sr=sample_rate, hop_length=hop_length)\n",
        "            \n",
        "            # Start row of data for line segment\n",
        "            row = f'{filename} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(spec_ro)} {np.mean(chroma_stft)} {np.mean(zcr)} {np.mean(tpg)}'                \n",
        "            \n",
        "            \n",
        "            # Extract mfcc\n",
        "            mfcc = librosa.feature.mfcc(y=signal[start:finish], \\\n",
        "                                        sr=sample_rate, n_mfcc=num_mfcc \\\n",
        "                                        , hop_length=hop_length)\n",
        "            # Append mfcc data to row\n",
        "            # if (len(mfcc) == num_mfcc_vectors_per_segment):\n",
        "            for c in mfcc:\n",
        "              row += f' {np.mean(c)}'\n",
        "            \n",
        "            row += f' {genre_label}'\n",
        "            output = open(output_path, 'a', newline='')\n",
        "            row = row.split()\n",
        "            with output:\n",
        "              writer = csv.writer(output)\n",
        "              writer.writerow(row)\n",
        "          except Exception:\n",
        "            print(filename, 'start-finish:', start, '-', finish)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def extract_features_rnn(data_path=DATA_PATH, output_path=RNN_FEATURES,\n",
        "                         num_mfcc=13, n_fft=2048, hop_length=512, num_segments=10):\n",
        "  \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n",
        "        :param dataset_path (str): Path to dataset\n",
        "        :param json_path (str): Path to json file used to save MFCCs\n",
        "        :param num_mfcc (int): Number of coefficients to extract\n",
        "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
        "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
        "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
        "        :return None\n",
        "        \"\"\"\n",
        "\n",
        "  # dictionary to store mapping, labels, and MFCCs\n",
        "  data = {\n",
        "      \"mapping\": [],\n",
        "      \"labels\": [],\n",
        "      \"mfcc\": []\n",
        "  }\n",
        "\n",
        "  samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "  num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        " \n",
        "  # loop through all genre sub-folder\n",
        "  for i, (dirpath, dirnames, filenames) in enumerate(os.walk(data_path)):\n",
        "\n",
        "    \n",
        "    # ensure we're processing a genre sub-folder level\n",
        "    if dirpath is not data_path and os.path.isdir(dirpath):\n",
        "      \n",
        "      # save genre label (i.e., sub-folder name) in the mapping\n",
        "      semantic_label = dirpath.split(\"/\")[-1]\n",
        "      data[\"mapping\"].append(semantic_label)\n",
        "      print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "      \n",
        "      # process all audio files in genre sub-dir\n",
        "      for f in filenames:\n",
        "\n",
        "        # load audio file\n",
        "        file_path = os.path.join(dirpath, f)\n",
        "        signal, sample_rate = None, None\n",
        "        try:\n",
        "          signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "        except Exception:\n",
        "          print(f'librosa.load() error -file_path {file_path}')\n",
        "          continue\n",
        "          \n",
        "        # process all segments of audio file\n",
        "        for d in range(num_segments):\n",
        "          # calculate start and finish sample for current segment\n",
        "          start = samples_per_segment * d\n",
        "          finish = start + samples_per_segment\n",
        "          try:\n",
        "            \n",
        "            # extract mfcc\n",
        "            mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, \\\n",
        "                                        n_mfcc=num_mfcc, n_fft=n_fft, \\\n",
        "                                        hop_length=hop_length)\n",
        "            mfcc = mfcc.T\n",
        "            \n",
        "            # store only mfcc feature with expected number of vectors\n",
        "            if len(mfcc) == num_mfcc_vectors_per_segment:\n",
        "              data[\"mfcc\"].append(mfcc.tolist())\n",
        "              data[\"labels\"].append(i-1)\n",
        "          except Exception:\n",
        "            print(f, 'start-finish:', start, '-', finish)\n",
        "            \n",
        "  # save MFCCs to json file\n",
        "  with open(output_path, \"w\") as fp:\n",
        "    json.dump(data, fp, indent=4)\n",
        "\n",
        "\n",
        "def extract_features_cnn(data_path=DATA_PATH, output_path=CNN_FEATURES,\n",
        "                         num_mfcc=13, n_fft=2048, hop_length=512, num_segments=10):\n",
        "  \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n",
        "        :param dataset_path (str): Path to dataset\n",
        "        :param json_path (str): Path to json file used to save MFCCs\n",
        "        :param num_mfcc (int): Number of coefficients to extract\n",
        "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
        "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
        "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
        "        :return None\n",
        "        \"\"\"\n",
        "\n",
        "  # dictionary to store mapping, labels, and MFCCs\n",
        "  data = {\n",
        "      \"mapping\": [],\n",
        "      \"labels\": [],\n",
        "      \"log_spec\": []\n",
        "  }\n",
        "\n",
        "  # Create np array logs of melspectrograms\n",
        "  spects = np.empty((0, 130, 128))\n",
        "  \n",
        "\n",
        "  samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        " \n",
        "  # loop through all genre sub-folder\n",
        "  for i, (dirpath, dirnames, filenames) in enumerate(os.walk(data_path)):\n",
        "    semantic_label = dirpath.split(\"/\")[-1]\n",
        "    \n",
        "    # ensure we're processing a genre sub-folder level\n",
        "    if dirpath is not data_path and os.path.isdir(dirpath) and semantic_label in GENRE_NAMES:\n",
        "      \n",
        "      # save genre label (i.e., sub-folder name) in the mapping\n",
        "      semantic_label = dirpath.split(\"/\")[-1]\n",
        "      data[\"mapping\"].append(semantic_label)\n",
        "      print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "      \n",
        "      # process all audio files in genre sub-dir\n",
        "      for f in filenames:\n",
        "\n",
        "        # load audio file\n",
        "        file_path = os.path.join(dirpath, f)\n",
        "        signal, sample_rate = None, None\n",
        "        try:\n",
        "          signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "        except Exception:\n",
        "          print(f'librosa.load() error -file_path {file_path}')\n",
        "          continue\n",
        "          \n",
        "        # process all segments of audio file\n",
        "        for d in range(num_segments):\n",
        "          \n",
        "          # calculate start and finish sample for current segment\n",
        "          start = samples_per_segment * d\n",
        "          finish = start + samples_per_segment\n",
        "          try:\n",
        "              spect = librosa.feature.melspectrogram(signal[start:finish], \n",
        "                                                     sr=sample_rate,n_fft=n_fft, hop_length=hop_length)\n",
        "              spect = librosa.power_to_db(spect, ref=np.max)\n",
        "              spect = spect.T\n",
        "              spect = spect[:130, :]\n",
        "              spects = np.append(spects, [spect], axis=0)\n",
        "              print(spects.shape)\n",
        "              # data[\"labels\"].append(i-1)\n",
        "          except Exception as e:\n",
        "            print(e)\n",
        "            print(f, 'start-finish:', start, '-', finish)\n",
        "  data[\"log_spec\"] = spects.tolist()\n",
        "  save log_specs to json file\n",
        "  with open(output_path, \"w\") as fp:\n",
        "    json.dump(data, fp, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KwhBpRc2v_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3139e91e-a389-4d91-dbea-986646e78dc5"
      },
      "source": [
        "# Extract features for each type of classifier into csv, json, and json files respectively\n",
        "extract_features_MLP()\n",
        "extract_features_rnn()\n",
        "extract_features_cnn()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Processing: rumba\n",
            "rumba0000.wav start-finish: 529200 - 595350\n",
            "rumba0000.wav start-finish: 595350 - 661500\n",
            "rumba00010.wav start-finish: 529200 - 595350\n",
            "rumba00010.wav start-finish: 595350 - 661500\n",
            "rumba00011.wav start-finish: 463050 - 529200\n",
            "rumba00011.wav start-finish: 529200 - 595350\n",
            "rumba00011.wav start-finish: 595350 - 661500\n",
            "rumba00014.wav start-finish: 595350 - 661500\n",
            "rumba00043.wav start-finish: 396900 - 463050\n",
            "rumba00043.wav start-finish: 463050 - 529200\n",
            "rumba00043.wav start-finish: 529200 - 595350\n",
            "rumba00043.wav start-finish: 595350 - 661500\n",
            "rumba00052.wav start-finish: 595350 - 661500\n",
            "rumba00059.wav start-finish: 330750 - 396900\n",
            "rumba00059.wav start-finish: 396900 - 463050\n",
            "rumba00059.wav start-finish: 463050 - 529200\n",
            "rumba00059.wav start-finish: 529200 - 595350\n",
            "rumba00059.wav start-finish: 595350 - 661500\n",
            "rumba00062.wav start-finish: 595350 - 661500\n",
            "rumba00087.wav start-finish: 198450 - 264600\n",
            "rumba00087.wav start-finish: 264600 - 330750\n",
            "rumba00087.wav start-finish: 330750 - 396900\n",
            "rumba00087.wav start-finish: 396900 - 463050\n",
            "rumba00087.wav start-finish: 463050 - 529200\n",
            "rumba00087.wav start-finish: 529200 - 595350\n",
            "rumba00087.wav start-finish: 595350 - 661500\n",
            "rumba00096.wav start-finish: 198450 - 264600\n",
            "rumba00096.wav start-finish: 264600 - 330750\n",
            "rumba00096.wav start-finish: 330750 - 396900\n",
            "rumba00096.wav start-finish: 396900 - 463050\n",
            "rumba00096.wav start-finish: 463050 - 529200\n",
            "rumba00096.wav start-finish: 529200 - 595350\n",
            "rumba00096.wav start-finish: 595350 - 661500\n",
            "rumba00099.wav start-finish: 396900 - 463050\n",
            "rumba00099.wav start-finish: 463050 - 529200\n",
            "rumba00099.wav start-finish: 529200 - 595350\n",
            "rumba00099.wav start-finish: 595350 - 661500\n",
            "\n",
            "Processing: disco\n",
            "disco.00014.wav start-finish: 595350 - 661500\n",
            "\n",
            "Processing: rock\n",
            "\n",
            "Processing: classical\n",
            "classical.00051.wav start-finish: 595350 - 661500\n",
            "\n",
            "Processing: metal\n",
            "\n",
            "Processing: afrobeat\n",
            "afrobeat0003.wav start-finish: 529200 - 595350\n",
            "afrobeat0003.wav start-finish: 595350 - 661500\n",
            "afrobeat0006.wav start-finish: 396900 - 463050\n",
            "afrobeat0006.wav start-finish: 463050 - 529200\n",
            "afrobeat0006.wav start-finish: 529200 - 595350\n",
            "afrobeat0006.wav start-finish: 595350 - 661500\n",
            "afrobeat00024.wav start-finish: 330750 - 396900\n",
            "afrobeat00024.wav start-finish: 396900 - 463050\n",
            "afrobeat00024.wav start-finish: 463050 - 529200\n",
            "afrobeat00024.wav start-finish: 529200 - 595350\n",
            "afrobeat00024.wav start-finish: 595350 - 661500\n",
            "afrobeat00028.wav start-finish: 198450 - 264600\n",
            "afrobeat00028.wav start-finish: 264600 - 330750\n",
            "afrobeat00028.wav start-finish: 330750 - 396900\n",
            "afrobeat00028.wav start-finish: 396900 - 463050\n",
            "afrobeat00028.wav start-finish: 463050 - 529200\n",
            "afrobeat00028.wav start-finish: 529200 - 595350\n",
            "afrobeat00028.wav start-finish: 595350 - 661500\n",
            "afrobeat00039.wav start-finish: 330750 - 396900\n",
            "afrobeat00039.wav start-finish: 396900 - 463050\n",
            "afrobeat00039.wav start-finish: 463050 - 529200\n",
            "afrobeat00039.wav start-finish: 529200 - 595350\n",
            "afrobeat00039.wav start-finish: 595350 - 661500\n",
            "afrobeat00044.wav start-finish: 330750 - 396900\n",
            "afrobeat00044.wav start-finish: 396900 - 463050\n",
            "afrobeat00044.wav start-finish: 463050 - 529200\n",
            "afrobeat00044.wav start-finish: 529200 - 595350\n",
            "afrobeat00044.wav start-finish: 595350 - 661500\n",
            "afrobeat00065.wav start-finish: 264600 - 330750\n",
            "afrobeat00065.wav start-finish: 330750 - 396900\n",
            "afrobeat00065.wav start-finish: 396900 - 463050\n",
            "afrobeat00065.wav start-finish: 463050 - 529200\n",
            "afrobeat00065.wav start-finish: 529200 - 595350\n",
            "afrobeat00065.wav start-finish: 595350 - 661500\n",
            "afrobeat00085.wav start-finish: 463050 - 529200\n",
            "afrobeat00085.wav start-finish: 529200 - 595350\n",
            "afrobeat00085.wav start-finish: 595350 - 661500\n",
            "afrobeat00094.wav start-finish: 595350 - 661500\n",
            "\n",
            "Processing: pop\n",
            "\n",
            "Processing: reggae\n",
            "\n",
            "Processing: blues\n",
            "\n",
            "Processing: coupe_decale\n",
            "coupe_decale0002.wav start-finish: 198450 - 264600\n",
            "coupe_decale0002.wav start-finish: 264600 - 330750\n",
            "coupe_decale0002.wav start-finish: 330750 - 396900\n",
            "coupe_decale0002.wav start-finish: 396900 - 463050\n",
            "coupe_decale0002.wav start-finish: 463050 - 529200\n",
            "coupe_decale0002.wav start-finish: 529200 - 595350\n",
            "coupe_decale0002.wav start-finish: 595350 - 661500\n",
            "coupe_decale0004.wav start-finish: 396900 - 463050\n",
            "coupe_decale0004.wav start-finish: 463050 - 529200\n",
            "coupe_decale0004.wav start-finish: 529200 - 595350\n",
            "coupe_decale0004.wav start-finish: 595350 - 661500\n",
            "coupe_decale00035.wav start-finish: 264600 - 330750\n",
            "coupe_decale00035.wav start-finish: 330750 - 396900\n",
            "coupe_decale00035.wav start-finish: 396900 - 463050\n",
            "coupe_decale00035.wav start-finish: 463050 - 529200\n",
            "coupe_decale00035.wav start-finish: 529200 - 595350\n",
            "coupe_decale00035.wav start-finish: 595350 - 661500\n",
            "coupe_decale00039.wav start-finish: 463050 - 529200\n",
            "coupe_decale00039.wav start-finish: 529200 - 595350\n",
            "coupe_decale00039.wav start-finish: 595350 - 661500\n",
            "coupe_decale00041.wav start-finish: 529200 - 595350\n",
            "coupe_decale00041.wav start-finish: 595350 - 661500\n",
            "coupe_decale00061.wav start-finish: 463050 - 529200\n",
            "coupe_decale00061.wav start-finish: 529200 - 595350\n",
            "coupe_decale00061.wav start-finish: 595350 - 661500\n",
            "coupe_decale00068.wav start-finish: 330750 - 396900\n",
            "coupe_decale00068.wav start-finish: 396900 - 463050\n",
            "coupe_decale00068.wav start-finish: 463050 - 529200\n",
            "coupe_decale00068.wav start-finish: 529200 - 595350\n",
            "coupe_decale00068.wav start-finish: 595350 - 661500\n",
            "coupe_decale00073.wav start-finish: 198450 - 264600\n",
            "coupe_decale00073.wav start-finish: 264600 - 330750\n",
            "coupe_decale00073.wav start-finish: 330750 - 396900\n",
            "coupe_decale00073.wav start-finish: 396900 - 463050\n",
            "coupe_decale00073.wav start-finish: 463050 - 529200\n",
            "coupe_decale00073.wav start-finish: 529200 - 595350\n",
            "coupe_decale00073.wav start-finish: 595350 - 661500\n",
            "\n",
            "Processing: hiphop\n",
            "\n",
            "Processing: jazz\n",
            "librosa.load() error -file_path /content/drive/My Drive/Apollo's Ear/data/genres/jazz/jazz.00054.wav\n",
            "\n",
            "Processing: country\n",
            "country.00007.wav start-finish: 595350 - 661500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vyZWiWOhqhK"
      },
      "source": [
        "# Classifiers Utilities\n",
        "The following funtions help with loading features data, transforming them into training format, and building models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3FZ9Jn3ioLc"
      },
      "source": [
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import random\n",
        "import pickle\n",
        "import joblib\n",
        "\n",
        "def load_csv(data_path,label_column, print_mappings=False):\n",
        "  \"\"\"Loads training dataset from json file. Used for MLP data\n",
        "      :param data_path (str): Path to json file containing data\n",
        "      :return X (ndarray): Inputs\n",
        "      :return y (ndarray): Targets\n",
        "  \"\"\"\n",
        "  # Read data into Pandas, drop useless columns, scale  \n",
        "  data = pd.read_csv(data_path)\n",
        "  data = data.drop([label_column], axis=1)\n",
        "  data = data.dropna()\n",
        "  genre_list = data.iloc[:,-1]\n",
        "  encoder = LabelEncoder()\n",
        "  y = encoder.fit_transform(genre_list) \n",
        "  if print_mappings:\n",
        "    mappings = encoder.inverse_transform([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "    print(\n",
        "        {\n",
        "            0: mappings[0],\n",
        "            1: mappings[1],\n",
        "            2: mappings[2],\n",
        "            3: mappings[3],\n",
        "            4: mappings[4],\n",
        "            5: mappings[5],\n",
        "            6: mappings[6],\n",
        "            7: mappings[7],\n",
        "            8: mappings[8],\n",
        "            9: mappings[9],\n",
        "            10: mappings[10],\n",
        "            11: mappings[11],\n",
        "            12: mappings[12]\n",
        "        }\n",
        "    )\n",
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "  return X, y\n",
        "\n",
        "def load_json(data_path, x_label, y_label, print_mappings=False, mappings_name=None):\n",
        "  \"\"\"Loads training dataset from json file. Used for RNN and (later) CNN features\n",
        "      :param data_path (str): Path to json file containing data\n",
        "      :return X (ndarray): Inputs\n",
        "      :return y (ndarray): Targets\n",
        "  \"\"\"\n",
        "  with open(data_path, \"r\") as fp:\n",
        "      data = json.load(fp)\n",
        "  X = np.array(data[x_label])\n",
        "  y = np.array(data[y_label])\n",
        "  if print_mappings:\n",
        "    mappings = data[mappings_name]\n",
        "    print(\n",
        "        {\n",
        "            0: mappings[0],\n",
        "            1: mappings[1],\n",
        "            2: mappings[2],\n",
        "            3: mappings[3],\n",
        "            4: mappings[4],\n",
        "            5: mappings[5],\n",
        "            6: mappings[6],\n",
        "            7: mappings[7],\n",
        "            8: mappings[8],\n",
        "            9: mappings[9],\n",
        "            10: mappings[10],\n",
        "            11: mappings[11],\n",
        "            12: mappings[12]\n",
        "        }\n",
        "    )\n",
        "  return X, y\n",
        "\n",
        "def save_model_to_disk(model, method='pickle', output_path=None):\n",
        "  \"\"\"\n",
        "    Saves model to disk using pickle or joblib\n",
        "    :param model ML model\n",
        "    :param method (serialization method) Default is 'pickle'. You can also choose\n",
        "      joylib. The function will pick pickle if parameter starts with p, and joylib\n",
        "      if it sarts with j. Anything else and pickle is picked\n",
        "    :param output_path: path to save the model at. Creates a random name in working folder otherwise\n",
        "    :returns final output_path if file successfully saved\n",
        "  \"\"\"\n",
        "  if not output_path:\n",
        "    ouptut_path = f'{WORKING_FOLDER}/model{random.randint(1000000)}.sav'\n",
        " \n",
        "  writer = open(output_path, 'wb')\n",
        "  \n",
        "  if method[0] == 'j':\n",
        "    joblib.dump(model, writer)\n",
        "  \n",
        "  else:\n",
        "    pickle.dump(model, writer)\n",
        "    return output_path\n",
        "  \n",
        "    return output_path\n",
        "\n",
        "def load_model_from_disk(method='pickle', file_path=None):\n",
        "  \"\"\"\n",
        "    Loads model from disk using pickle or joblib\n",
        "    :param model (ML model. Default is self.model)\n",
        "    :param method Default is 'pickle' Other accepted is 'p (pickle), joblib, j\n",
        "      for joblib.\n",
        "    :param file_path: path to load the model from \n",
        "    :return: True if model successfully loaded and False otherwise\n",
        "  \"\"\"\n",
        "  if not file_path:\n",
        "    raise Exception(\"file_path is required\")\n",
        "  if method[0] == 'j':\n",
        "    return joblib.load(model, file_path)\n",
        "  \n",
        "  else:\n",
        "    return pickle.load(model, file_path)\n",
        "\n",
        "def prepare_dataset(data, test_size=0.25, validation_size=0.2):\n",
        "  \"\"\"loads data and splits it into in training set and test set\n",
        "  :param test_size (float): fraction of data to allocate to testing\n",
        "  :param validation_size (float): fraction of data to allocate to validation\n",
        "  \n",
        "  :return X_train (ndarray): Input training set\n",
        "  :return X_validation (ndarray): Input validation set\n",
        "  :return X_test (ndarray): Input test set\n",
        "  :return Y_train (ndarray): Target test set\n",
        "  :return y_validation (ndarray): Target Validation set\n",
        "  :return y_test (ndarray): Target test set\n",
        "  \"\"\"\n",
        "  X, y = data\n",
        "  # create train, validation and test split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "  X_train, X_validation, y_train, y_validation = \\\n",
        "  train_test_split(X_train, y_train, test_size=validation_size)\n",
        "  X_train, y_train = X_train, y_train\n",
        "  X_test, y_test = X_test, y_test\n",
        "  X_validation, y_validation = X_validation, y_validation\n",
        "  return X_train, X_validation, X_test, y_train, y_validation, y_test\n",
        "  \n",
        "  \n",
        "def build_model(model=keras.Sequential(), layers=[]):\n",
        "  \"\"\" Simple Abstraction to build model. \n",
        "  :model model to build\n",
        "  :layers list of layers ordered from first at layers[0] to output at layers[1]\n",
        "  :return model: model with appended layers\n",
        "  \"\"\"\n",
        "  if not model:\n",
        "    model = keras.Sequential()\n",
        "  for layer in layers:\n",
        "   model.add(layers[i])\n",
        "  return model\n",
        "\n",
        "def test_model(model=None, X_test=None, y_test=None, verbose=2):\n",
        "  \"\"\" Simple abstraction to tests model\n",
        "  :model (keras.Sequential) model to be tested. Must be compiled\n",
        "  :X_test (list) X testing data\n",
        "  :y_test (list) y testing data\n",
        "  \"\"\"\n",
        "  test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "  return test_loss, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBkCFAK7j19L"
      },
      "source": [
        "# Models\n",
        "Now that we have all the data and needed utility functions, we can create and\n",
        "train the models. \n",
        "*   First Model: A simple Multi Layer Perceptron.\n",
        "*   Second Model: A Convolutional Neural Network\n",
        "*   First Model: A Recursive Neural Network with short term longterm memory\n",
        "\n",
        "\n",
        "The target is 80% testing accuracy for each of the models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6Asfh79kmWb"
      },
      "source": [
        "## MLP\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aNDMYtUTtdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd7d6e9-3cdf-4c39-fee8-436d4a46e6ca"
      },
      "source": [
        "# Get Mappings to go from predicted number to genre name\n",
        "load_csv(MLP_FEATURES, \"filename\", print_mappings=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'afrobeat', 1: 'blues', 2: 'classical', 3: 'country', 4: 'coupe_decale', 5: 'disco', 6: 'hiphop', 7: 'jazz', 8: 'metal', 9: 'pop', 10: 'reggae', 11: 'rock', 12: 'rumba'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.41151822, -0.51150616, -0.58490442, ..., -0.09453255,\n",
              "         -0.58875239, -0.61669917],\n",
              "        [-0.37699652, -0.47307609, -0.52076945, ..., -0.06483495,\n",
              "         -0.57393999, -0.44993348],\n",
              "        [-0.40711615, -0.29394659, -0.53136849, ...,  0.03502479,\n",
              "         -1.06283332, -0.58127863],\n",
              "        ...,\n",
              "        [-1.13627439, -1.17357946, -1.11512645, ..., -0.74544044,\n",
              "          0.77776533, -0.23036586],\n",
              "        [-1.19165672, -1.16376193, -1.10266177, ..., -0.81761482,\n",
              "         -0.15126182, -0.16570641],\n",
              "        [-1.28323919, -1.23439329, -1.19824234, ..., -0.66512694,\n",
              "         -0.1610514 , -0.58482315]]), array([12, 12, 12, ...,  3,  3,  3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edTj9L1RkkcV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "400223e2-1c35-46f0-8a65-923457800e0d"
      },
      "source": [
        "### Prepate data set ###\n",
        "data = load_csv(MLP_FEATURES, 'filename')\n",
        "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_dataset(data)\n",
        "\n",
        "#### Create network ####\n",
        "input_shape=(X_train.shape[1],)\n",
        "\n",
        "# Initialize MLP and add hidden layers\n",
        "mlp_model = keras.Sequential()\n",
        "mlp_model.add(keras.layers.Dense(512, activation='relu', input_shape=input_shape))\n",
        "mlp_model.add(keras.layers.Dense(512, activation='relu', input_shape=input_shape))\n",
        "mlp_model.add(keras.layers.Dense(256, activation='relu', input_shape=input_shape))\n",
        "mlp_model.add(keras.layers.Dense(256, activation='relu', input_shape=input_shape))\n",
        "mlp_model.add(keras.layers.Dense(256, activation='relu', input_shape=input_shape))\n",
        "mlp_model.add(keras.layers.Dense(128, activation='relu'))\n",
        "mlp_model.add(keras.layers.Dense(128, activation='relu'))\n",
        "mlp_model.add(keras.layers.Dense(64, activation='relu'))\n",
        "mlp_model.add(keras.layers.Dense(64, activation='relu'))\n",
        "\n",
        "# Add output layer\n",
        "mlp_model.add(keras.layers.Dense(13, activation='softmax'))\n",
        "\n",
        "# Compile Model\n",
        "mlp_model.compile(keras.optimizers.Adam(learning_rate=0.0001), \n",
        "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "history = mlp_model.fit(X_train, y_train, validation_data=(X_validation, y_validation), \\\n",
        "                    batch_size=50, epochs=100)\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = mlp_model.evaluate(X_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 2.4404 - accuracy: 0.1722 - val_loss: 2.2374 - val_accuracy: 0.2683\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8289 - accuracy: 0.3934 - val_loss: 1.5986 - val_accuracy: 0.4386\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.4481 - accuracy: 0.5008 - val_loss: 1.4236 - val_accuracy: 0.5119\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 1.2927 - accuracy: 0.5493 - val_loss: 1.3457 - val_accuracy: 0.5459\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.1932 - accuracy: 0.5813 - val_loss: 1.2917 - val_accuracy: 0.5501\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 1.1183 - accuracy: 0.6144 - val_loss: 1.2387 - val_accuracy: 0.5820\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 1.0581 - accuracy: 0.6353 - val_loss: 1.2211 - val_accuracy: 0.5697\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.0368 - accuracy: 0.6415 - val_loss: 1.1824 - val_accuracy: 0.5996\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.9682 - accuracy: 0.6626 - val_loss: 1.1486 - val_accuracy: 0.5934\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.9287 - accuracy: 0.6799 - val_loss: 1.1403 - val_accuracy: 0.6099\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.8875 - accuracy: 0.6890 - val_loss: 1.0833 - val_accuracy: 0.6336\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.8528 - accuracy: 0.7039 - val_loss: 1.0775 - val_accuracy: 0.6171\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.8354 - accuracy: 0.7106 - val_loss: 1.0707 - val_accuracy: 0.6213\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.8071 - accuracy: 0.7078 - val_loss: 1.0326 - val_accuracy: 0.6460\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.7659 - accuracy: 0.7290 - val_loss: 1.0492 - val_accuracy: 0.6388\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7442 - val_loss: 1.0017 - val_accuracy: 0.6543\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.7183 - accuracy: 0.7494 - val_loss: 0.9792 - val_accuracy: 0.6543\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.7099 - accuracy: 0.7496 - val_loss: 0.9852 - val_accuracy: 0.6605\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.7692 - val_loss: 0.9945 - val_accuracy: 0.6553\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.7749 - val_loss: 0.9679 - val_accuracy: 0.6584\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7901 - val_loss: 0.9496 - val_accuracy: 0.6791\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.7881 - val_loss: 0.9394 - val_accuracy: 0.6791\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7979 - val_loss: 0.9737 - val_accuracy: 0.6687\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.8038 - val_loss: 0.9728 - val_accuracy: 0.6605\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.8209 - val_loss: 0.9213 - val_accuracy: 0.7018\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.8245 - val_loss: 0.9102 - val_accuracy: 0.6914\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.8273 - val_loss: 0.9296 - val_accuracy: 0.6842\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.8389 - val_loss: 0.9153 - val_accuracy: 0.6832\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.8371 - val_loss: 0.9481 - val_accuracy: 0.6863\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.8418 - val_loss: 0.9543 - val_accuracy: 0.6863\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8526 - val_loss: 0.9361 - val_accuracy: 0.6904\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8748 - val_loss: 0.9309 - val_accuracy: 0.7162\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8712 - val_loss: 0.9168 - val_accuracy: 0.7069\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8733 - val_loss: 0.9638 - val_accuracy: 0.6842\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8743 - val_loss: 0.8960 - val_accuracy: 0.7121\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8862 - val_loss: 0.9380 - val_accuracy: 0.7059\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8965 - val_loss: 0.9006 - val_accuracy: 0.7224\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.2992 - accuracy: 0.9032 - val_loss: 0.8750 - val_accuracy: 0.7276\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.9089 - val_loss: 0.9053 - val_accuracy: 0.7183\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.2909 - accuracy: 0.9009 - val_loss: 0.9165 - val_accuracy: 0.7131\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.2818 - accuracy: 0.9032 - val_loss: 0.8785 - val_accuracy: 0.7286\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.9109 - val_loss: 0.9263 - val_accuracy: 0.7296\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.9128 - val_loss: 0.9674 - val_accuracy: 0.7203\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.2182 - accuracy: 0.9290 - val_loss: 0.9151 - val_accuracy: 0.7296\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.2390 - accuracy: 0.9171 - val_loss: 0.9141 - val_accuracy: 0.7296\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.2082 - accuracy: 0.9339 - val_loss: 0.9742 - val_accuracy: 0.7162\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.2112 - accuracy: 0.9288 - val_loss: 0.8868 - val_accuracy: 0.7327\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1951 - accuracy: 0.9370 - val_loss: 0.9751 - val_accuracy: 0.7193\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 0.9504 - val_loss: 0.9218 - val_accuracy: 0.7420\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1547 - accuracy: 0.9530 - val_loss: 0.9107 - val_accuracy: 0.7482\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9445 - val_loss: 0.9328 - val_accuracy: 0.7472\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1516 - accuracy: 0.9546 - val_loss: 0.9691 - val_accuracy: 0.7234\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1677 - accuracy: 0.9476 - val_loss: 0.9886 - val_accuracy: 0.7245\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1501 - accuracy: 0.9525 - val_loss: 0.9851 - val_accuracy: 0.7379\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9672 - val_loss: 0.9155 - val_accuracy: 0.7482\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1088 - accuracy: 0.9670 - val_loss: 1.0120 - val_accuracy: 0.7420\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.9613 - val_loss: 1.0169 - val_accuracy: 0.7337\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9618 - val_loss: 1.1012 - val_accuracy: 0.7327\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1049 - accuracy: 0.9695 - val_loss: 0.9682 - val_accuracy: 0.7503\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9726 - val_loss: 1.0311 - val_accuracy: 0.7451\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0804 - accuracy: 0.9796 - val_loss: 1.0501 - val_accuracy: 0.7513\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9783 - val_loss: 1.0555 - val_accuracy: 0.7575\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9812 - val_loss: 0.9973 - val_accuracy: 0.7668\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.9814 - val_loss: 1.1923 - val_accuracy: 0.7348\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.9654 - val_loss: 1.0260 - val_accuracy: 0.7482\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0884 - accuracy: 0.9734 - val_loss: 1.0500 - val_accuracy: 0.7523\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9819 - val_loss: 1.1303 - val_accuracy: 0.7461\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9822 - val_loss: 1.1373 - val_accuracy: 0.7595\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9889 - val_loss: 1.1250 - val_accuracy: 0.7544\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9848 - val_loss: 1.1187 - val_accuracy: 0.7657\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9822 - val_loss: 1.1579 - val_accuracy: 0.7585\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9861 - val_loss: 1.2427 - val_accuracy: 0.7368\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9866 - val_loss: 1.1534 - val_accuracy: 0.7482\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9907 - val_loss: 1.1808 - val_accuracy: 0.7513\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9897 - val_loss: 1.1736 - val_accuracy: 0.7441\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9739 - val_loss: 1.2362 - val_accuracy: 0.7492\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9768 - val_loss: 1.1467 - val_accuracy: 0.7616\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9775 - val_loss: 1.2489 - val_accuracy: 0.7420\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9910 - val_loss: 1.1837 - val_accuracy: 0.7657\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9858 - val_loss: 1.1990 - val_accuracy: 0.7647\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9951 - val_loss: 1.2054 - val_accuracy: 0.7688\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9959 - val_loss: 1.1273 - val_accuracy: 0.7792\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9801 - val_loss: 1.3172 - val_accuracy: 0.7399\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9793 - val_loss: 1.4777 - val_accuracy: 0.7245\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 1.2051 - val_accuracy: 0.7637\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9964 - val_loss: 1.2203 - val_accuracy: 0.7657\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9946 - val_loss: 1.1869 - val_accuracy: 0.7740\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 1.2087 - val_accuracy: 0.7657\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9796 - val_loss: 1.3160 - val_accuracy: 0.7451\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9861 - val_loss: 1.2488 - val_accuracy: 0.7699\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9959 - val_loss: 1.3047 - val_accuracy: 0.7575\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9974 - val_loss: 1.2529 - val_accuracy: 0.7678\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 1.2359 - val_accuracy: 0.7781\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990 - val_loss: 1.2624 - val_accuracy: 0.7792\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 1.3293 - val_accuracy: 0.7637\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9933 - val_loss: 1.4169 - val_accuracy: 0.7441\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9670 - val_loss: 1.5899 - val_accuracy: 0.7110\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.1699 - accuracy: 0.9473 - val_loss: 1.4094 - val_accuracy: 0.7286\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9886 - val_loss: 1.1517 - val_accuracy: 0.7709\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9990 - val_loss: 1.1788 - val_accuracy: 0.7802\n",
            "51/51 - 0s - loss: 1.0298 - accuracy: 0.7981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srgLe4NiDVsr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2081949-da4e-4884-a138-2a90398c87a7"
      },
      "source": [
        "# We now save the models having reached our target accuracy\n",
        "mlp_model.save(f'{WORKING_FOLDER}/saved_models/mlp_model0')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Apollo's Ear/saved_models/mlp_model0/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNl5DqjRsdrV"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fuv9RerDSAkv"
      },
      "source": [
        "X, y = load_json(CNN_FEATURES, 'log_spec', 'labels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZikOyCgGa999",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9121d33a-b99f-4ca2-be78-d9e76d4adb76"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_validation = X_validation[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n",
        "\n",
        "#### Create network ####\n",
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "cnn_model = keras.Sequential()\n",
        "\n",
        "# 1st conv layer\n",
        "cnn_model.add(keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))\n",
        "cnn_model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "cnn_model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# 2nd conv layer\n",
        "cnn_model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "cnn_model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "cnn_model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# 3rd conv layer\n",
        "cnn_model.add(keras.layers.Conv2D(64, (2, 2), activation='relu'))\n",
        "cnn_model.add(keras.layers.MaxPooling2D((4, 4), strides=(2, 2), padding='same'))\n",
        "cnn_model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# 4th conv layer\n",
        "cnn_model.add(keras.layers.Conv2D(128, (2, 2), activation='relu'))\n",
        "cnn_model.add(keras.layers.MaxPooling2D((4, 4), strides=(2, 2), padding='same'))\n",
        "cnn_model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# flatten output and feed it into dense layer\n",
        "cnn_model.add(keras.layers.Flatten())\n",
        "\n",
        "cnn_model.add(keras.layers.Dense(128, activation='relu'))\n",
        "cnn_model.add(keras.layers.Dropout(0.3))\n",
        "    \n",
        "cnn_model.add(keras.layers.Dense(128, activation='relu'))\n",
        "cnn_model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "# output layer\n",
        "cnn_model.add(keras.layers.Dense(13, activation='softmax'))\n",
        "\n",
        "# Compile cnn_model\n",
        "cnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train cnn_model\n",
        "history = cnn_model.fit(X_train, y_train, validation_data=(X_validation, y_validation), \\\n",
        "                    batch_size=50, epochs=100)\n",
        "\n",
        "# Evaluate cnn_model\n",
        "test_loss, test_acc = cnn_model.evaluate(X_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 2.2650 - accuracy: 0.2510 - val_loss: 2.2633 - val_accuracy: 0.2453\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 1.8453 - accuracy: 0.3714 - val_loss: 1.5658 - val_accuracy: 0.5005\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 1.6076 - accuracy: 0.4591 - val_loss: 1.2809 - val_accuracy: 0.5927\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 1.4244 - accuracy: 0.5122 - val_loss: 1.1817 - val_accuracy: 0.6268\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 1.2533 - accuracy: 0.5764 - val_loss: 1.1437 - val_accuracy: 0.6408\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 1.1520 - accuracy: 0.6071 - val_loss: 1.0385 - val_accuracy: 0.6594\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 1.0317 - accuracy: 0.6567 - val_loss: 0.9529 - val_accuracy: 0.6900\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.9325 - accuracy: 0.6858 - val_loss: 0.9115 - val_accuracy: 0.7029\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.8570 - accuracy: 0.7170 - val_loss: 0.8762 - val_accuracy: 0.7086\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.7697 - accuracy: 0.7472 - val_loss: 0.8420 - val_accuracy: 0.7200\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.6771 - accuracy: 0.7725 - val_loss: 0.8514 - val_accuracy: 0.7133\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.6239 - accuracy: 0.7930 - val_loss: 0.8059 - val_accuracy: 0.7298\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.5513 - accuracy: 0.8204 - val_loss: 0.7819 - val_accuracy: 0.7386\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.4979 - accuracy: 0.8365 - val_loss: 0.7801 - val_accuracy: 0.7360\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.4538 - accuracy: 0.8542 - val_loss: 0.7888 - val_accuracy: 0.7391\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.4063 - accuracy: 0.8685 - val_loss: 0.7453 - val_accuracy: 0.7552\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.3726 - accuracy: 0.8764 - val_loss: 0.7599 - val_accuracy: 0.7510\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.3393 - accuracy: 0.8910 - val_loss: 0.8704 - val_accuracy: 0.7293\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.3072 - accuracy: 0.9012 - val_loss: 0.7495 - val_accuracy: 0.7547\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.2727 - accuracy: 0.9140 - val_loss: 0.7452 - val_accuracy: 0.7490\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.2489 - accuracy: 0.9206 - val_loss: 0.7864 - val_accuracy: 0.7453\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.2223 - accuracy: 0.9315 - val_loss: 0.7823 - val_accuracy: 0.7629\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.2076 - accuracy: 0.9353 - val_loss: 0.7940 - val_accuracy: 0.7521\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.1810 - accuracy: 0.9433 - val_loss: 0.8242 - val_accuracy: 0.7510\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.1686 - accuracy: 0.9485 - val_loss: 0.7378 - val_accuracy: 0.7671\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.1530 - accuracy: 0.9530 - val_loss: 0.7692 - val_accuracy: 0.7598\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.1362 - accuracy: 0.9610 - val_loss: 0.7954 - val_accuracy: 0.7754\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.1438 - accuracy: 0.9579 - val_loss: 0.8275 - val_accuracy: 0.7645\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.1360 - accuracy: 0.9548 - val_loss: 0.7950 - val_accuracy: 0.7692\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.1081 - accuracy: 0.9679 - val_loss: 0.7982 - val_accuracy: 0.7821\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.1067 - accuracy: 0.9674 - val_loss: 0.8840 - val_accuracy: 0.7629\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.1064 - accuracy: 0.9687 - val_loss: 0.8323 - val_accuracy: 0.7717\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0946 - accuracy: 0.9710 - val_loss: 0.7976 - val_accuracy: 0.7904\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0857 - accuracy: 0.9748 - val_loss: 0.8334 - val_accuracy: 0.7748\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0861 - accuracy: 0.9757 - val_loss: 0.8952 - val_accuracy: 0.7640\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0821 - accuracy: 0.9770 - val_loss: 0.8844 - val_accuracy: 0.7650\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0704 - accuracy: 0.9797 - val_loss: 0.8610 - val_accuracy: 0.7821\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0839 - accuracy: 0.9742 - val_loss: 0.9412 - val_accuracy: 0.7686\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0831 - accuracy: 0.9757 - val_loss: 0.8960 - val_accuracy: 0.7681\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0687 - accuracy: 0.9799 - val_loss: 0.8587 - val_accuracy: 0.7681\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9805 - val_loss: 0.8891 - val_accuracy: 0.7847\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0583 - accuracy: 0.9833 - val_loss: 0.9263 - val_accuracy: 0.7635\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0673 - accuracy: 0.9807 - val_loss: 0.9396 - val_accuracy: 0.7743\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0532 - accuracy: 0.9830 - val_loss: 0.9370 - val_accuracy: 0.7707\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0566 - accuracy: 0.9839 - val_loss: 0.9954 - val_accuracy: 0.7702\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0538 - accuracy: 0.9843 - val_loss: 0.9441 - val_accuracy: 0.7748\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0590 - accuracy: 0.9816 - val_loss: 0.9361 - val_accuracy: 0.7790\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0510 - accuracy: 0.9833 - val_loss: 0.9965 - val_accuracy: 0.7717\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0520 - accuracy: 0.9843 - val_loss: 0.9836 - val_accuracy: 0.7707\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0529 - accuracy: 0.9838 - val_loss: 0.9407 - val_accuracy: 0.7723\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0531 - accuracy: 0.9843 - val_loss: 0.9981 - val_accuracy: 0.7748\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0511 - accuracy: 0.9838 - val_loss: 0.9576 - val_accuracy: 0.7857\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0385 - accuracy: 0.9880 - val_loss: 1.0703 - val_accuracy: 0.7650\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0430 - accuracy: 0.9859 - val_loss: 1.0581 - val_accuracy: 0.7572\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 1.0059 - val_accuracy: 0.7805\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0465 - accuracy: 0.9854 - val_loss: 1.1389 - val_accuracy: 0.7635\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0410 - accuracy: 0.9868 - val_loss: 1.0889 - val_accuracy: 0.7681\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0448 - accuracy: 0.9860 - val_loss: 1.0867 - val_accuracy: 0.7717\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0406 - accuracy: 0.9893 - val_loss: 1.1198 - val_accuracy: 0.7712\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 1.0010 - val_accuracy: 0.7723\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0312 - accuracy: 0.9911 - val_loss: 1.2216 - val_accuracy: 0.7422\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 1.0494 - val_accuracy: 0.7743\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0399 - accuracy: 0.9865 - val_loss: 1.1941 - val_accuracy: 0.7572\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0321 - accuracy: 0.9896 - val_loss: 1.1202 - val_accuracy: 0.7686\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 1.0979 - val_accuracy: 0.7764\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0317 - accuracy: 0.9911 - val_loss: 1.0989 - val_accuracy: 0.7759\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 1.0828 - val_accuracy: 0.7650\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9891 - val_loss: 1.1252 - val_accuracy: 0.7697\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0321 - accuracy: 0.9894 - val_loss: 1.2219 - val_accuracy: 0.7484\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0308 - accuracy: 0.9916 - val_loss: 1.1462 - val_accuracy: 0.7795\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 1.2020 - val_accuracy: 0.7717\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0268 - accuracy: 0.9925 - val_loss: 1.1115 - val_accuracy: 0.7831\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0299 - accuracy: 0.9916 - val_loss: 1.1143 - val_accuracy: 0.7805\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 1.1262 - val_accuracy: 0.7805\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 1.1091 - val_accuracy: 0.7867\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 1.2562 - val_accuracy: 0.7619\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0291 - accuracy: 0.9909 - val_loss: 1.2492 - val_accuracy: 0.7728\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0243 - accuracy: 0.9934 - val_loss: 1.1816 - val_accuracy: 0.7671\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 1.2739 - val_accuracy: 0.7743\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0315 - accuracy: 0.9899 - val_loss: 1.1659 - val_accuracy: 0.7743\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 1.2754 - val_accuracy: 0.7676\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 1.1705 - val_accuracy: 0.7743\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0344 - accuracy: 0.9885 - val_loss: 1.4675 - val_accuracy: 0.7459\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 1.2146 - val_accuracy: 0.7790\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 1.2513 - val_accuracy: 0.7598\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 1.1930 - val_accuracy: 0.7655\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 1.3492 - val_accuracy: 0.7505\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 1.1428 - val_accuracy: 0.7888\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 1.1966 - val_accuracy: 0.7614\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 1.3135 - val_accuracy: 0.7505\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 1.1714 - val_accuracy: 0.7723\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 1.5581 - val_accuracy: 0.7448\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 1.2741 - val_accuracy: 0.7593\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 1.3128 - val_accuracy: 0.7629\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0222 - accuracy: 0.9939 - val_loss: 1.3398 - val_accuracy: 0.7635\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 1.2883 - val_accuracy: 0.7671\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0242 - accuracy: 0.9929 - val_loss: 1.3432 - val_accuracy: 0.7588\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 1.4230 - val_accuracy: 0.7479\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 1.3628 - val_accuracy: 0.7609\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 1.1319 - val_accuracy: 0.7883\n",
            "101/101 - 0s - loss: 1.1295 - accuracy: 0.7816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHcqKKmg2J_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2460011-f7cf-4542-9359-8053cfcb2a23"
      },
      "source": [
        "cnn_model.save(f'{WORKING_FOLDER}/saved_models/cnn_model0') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Apollo's Ear/saved_models/cnn_model0/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aOFd0_oiXKY"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bafjvHWaZcJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8ca30e-fc30-4f4b-f689-3725f90ce186"
      },
      "source": [
        "load_json(RNN_FEATURES, 'mfcc', 'labels', True, \"mapping\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'rumba', 1: 'disco', 2: 'rock', 3: 'classical', 4: 'metal', 5: 'afrobeat', 6: 'pop', 7: 'reggae', 8: 'blues', 9: 'coupe_decale', 10: 'hiphop', 11: 'jazz', 12: 'country'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[-6.74345979e+01,  8.61886238e+01, -5.63126121e+01, ...,\n",
              "           9.59944085e+00,  1.32054339e+01, -9.59345652e+00],\n",
              "         [-6.70991884e+01,  8.96536474e+01, -6.81074160e+01, ...,\n",
              "           3.29799698e+00,  8.84585181e+00, -1.38489561e+01],\n",
              "         [-9.46246495e+01,  8.70190556e+01, -7.36558894e+01, ...,\n",
              "          -1.65573091e+00,  2.42323777e+00, -1.23812869e+01],\n",
              "         ...,\n",
              "         [-8.01297808e+01,  1.11915974e+02, -4.87778241e+01, ...,\n",
              "          -7.04275847e+00, -1.21872338e+01, -1.73384663e+01],\n",
              "         [-1.12380499e+02,  1.01431415e+02, -5.39105163e+01, ...,\n",
              "          -5.56424746e+00, -8.17554298e+00, -8.84088402e+00],\n",
              "         [-1.28120083e+02,  1.02323599e+02, -4.90730915e+01, ...,\n",
              "           1.00002389e-01, -7.47547995e+00, -7.49481618e+00]],\n",
              " \n",
              "        [[-1.54917014e+02,  1.11043899e+02, -4.55737087e+01, ...,\n",
              "           2.84917382e+00, -1.02170351e+01, -3.02180252e+00],\n",
              "         [-1.42510638e+02,  1.15178886e+02, -2.53251768e+01, ...,\n",
              "          -5.37256595e+00, -7.59631036e+00, -8.86501387e+00],\n",
              "         [-8.56919772e+01,  1.15731478e+02, -4.99739149e+00, ...,\n",
              "          -4.76692743e+00, -4.97071215e+00, -1.60958098e+01],\n",
              "         ...,\n",
              "         [-1.64020784e+02,  6.90511106e+01, -3.37968500e+01, ...,\n",
              "          -7.99224328e+00, -3.16385411e+00, -1.15591543e+01],\n",
              "         [-1.57794663e+02,  7.83666438e+01, -3.87688656e+01, ...,\n",
              "          -1.57541756e-01,  3.43789505e+00, -1.00366387e+01],\n",
              "         [-1.36844389e+02,  9.76140834e+01, -4.21913822e+01, ...,\n",
              "           2.47560454e+00,  1.14448744e+01, -1.29405409e+01]],\n",
              " \n",
              "        [[-6.96480426e+01,  1.30881983e+02, -3.30633322e+01, ...,\n",
              "           1.36960593e+00, -9.00091687e-01, -2.29173282e+01],\n",
              "         [-7.38828725e+01,  1.22608540e+02, -3.13283927e+01, ...,\n",
              "          -1.79044183e+00,  2.34581411e+00, -1.83804505e+01],\n",
              "         [-1.08156623e+02,  1.08108009e+02, -2.34166683e+01, ...,\n",
              "          -2.32543525e+00,  1.00606705e+01, -1.48938058e+01],\n",
              "         ...,\n",
              "         [-1.20477724e+02,  9.53111156e+01, -2.26155947e+01, ...,\n",
              "          -8.31018470e-01,  9.61771540e+00, -1.73735694e+00],\n",
              "         [-1.19091631e+02,  9.95832002e+01, -2.61675784e+01, ...,\n",
              "          -1.34329693e+00,  1.14070286e+01,  4.00265197e+00],\n",
              "         [-1.10758613e+02,  1.11756610e+02, -3.01935729e+01, ...,\n",
              "           5.15620483e-01,  1.70594096e+01,  1.46158426e+01]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-1.03636140e+02,  1.51320990e+02, -2.60168874e+01, ...,\n",
              "          -1.62269031e+01,  6.93522294e+00,  8.86527169e+00],\n",
              "         [-1.10463269e+02,  1.51223380e+02, -3.00061307e+01, ...,\n",
              "          -2.04627553e+01,  7.49433505e+00,  6.53925134e+00],\n",
              "         [-1.21112116e+02,  1.44301586e+02, -3.69619188e+01, ...,\n",
              "          -2.42115596e+01,  6.00987894e+00,  2.57297744e+00],\n",
              "         ...,\n",
              "         [-4.71124798e+01,  1.62321772e+02, -5.79670629e+01, ...,\n",
              "           3.79254676e+00,  5.30422308e+00, -1.49557600e+01],\n",
              "         [-2.54415622e+01,  1.45426569e+02, -4.09521013e+01, ...,\n",
              "           3.63963118e+00,  1.54093505e+01, -1.55882647e+01],\n",
              "         [-2.85783586e+01,  1.41042931e+02, -3.08268633e+01, ...,\n",
              "           2.39001228e+00,  2.01495383e+01, -1.71516753e+01]],\n",
              " \n",
              "        [[-4.71463246e+01,  1.46996309e+02, -3.26639821e+01, ...,\n",
              "           1.29799640e+00,  7.33991493e+00, -1.18144103e+01],\n",
              "         [-5.83526465e+01,  1.58451917e+02, -3.81840655e+01, ...,\n",
              "           5.96654695e+00,  1.32489238e+01, -1.21591208e+01],\n",
              "         [-7.45968343e+01,  1.72738132e+02, -4.05821861e+01, ...,\n",
              "           6.29646176e+00,  1.29270376e+01, -8.38901564e+00],\n",
              "         ...,\n",
              "         [-1.25562507e+02,  1.51107460e+02, -1.98551800e+00, ...,\n",
              "          -1.56910091e+01, -3.24948059e+00, -3.39366960e+00],\n",
              "         [-1.33230652e+02,  1.58309157e+02, -3.14752612e+00, ...,\n",
              "          -1.64996505e+01, -9.36197435e+00, -8.61255784e+00],\n",
              "         [-1.31538374e+02,  1.59697066e+02,  3.79436988e+00, ...,\n",
              "          -1.18364653e+01, -1.19294191e+01, -1.35954882e+01]],\n",
              " \n",
              "        [[-9.78995306e+01,  1.74218696e+02, -2.37460641e+01, ...,\n",
              "          -6.92594909e+00, -1.97326830e+00,  2.32352542e-01],\n",
              "         [-1.15297523e+02,  1.73834268e+02, -2.65719321e+01, ...,\n",
              "          -9.50531065e+00, -3.62871391e+00, -4.14126366e+00],\n",
              "         [-1.39331832e+02,  1.64328097e+02, -2.61131590e+01, ...,\n",
              "          -1.14790865e+01, -8.63650326e+00, -1.01173307e+01],\n",
              "         ...,\n",
              "         [-4.78271629e+01,  1.63628718e+02, -4.16478051e+01, ...,\n",
              "          -1.69297438e+01,  8.62660258e+00, -3.77051252e+00],\n",
              "         [-4.04185861e+01,  1.63788461e+02, -4.15100381e+01, ...,\n",
              "          -1.40476119e+01,  4.38907022e+00,  7.51645758e-01],\n",
              "         [-3.06965190e+01,  1.59341111e+02, -3.36772832e+01, ...,\n",
              "          -1.01379885e+01,  7.72384422e+00,  6.20148314e+00]]]),\n",
              " array([ 0,  0,  0, ..., 12, 12, 12]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No59L57xslUy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0ba25d5-d1db-48e9-d895-5f2e05e20d8a"
      },
      "source": [
        "### Prepate data set ###\n",
        "X, y = load_json(RNN_FEATURES, 'mfcc', 'labels')\n",
        "\n",
        "# create train, validation and test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "\n",
        "#### Create network ####\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "# Initialize RNN-LSTM and add layers\n",
        "rnn_model = keras.Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "rnn_model.add(keras.layers.LSTM(512, input_shape=input_shape, return_sequences=True))\n",
        "rnn_model.add(keras.layers.LSTM(512, input_shape=input_shape, return_sequences=True))\n",
        "rnn_model.add(keras.layers.LSTM(256, input_shape=input_shape, return_sequences=True))\n",
        "rnn_model.add(keras.layers.LSTM(256, input_shape=input_shape, return_sequences=True))\n",
        "rnn_model.add(keras.layers.LSTM(128, input_shape=input_shape, return_sequences=True))\n",
        "rnn_model.add(keras.layers.LSTM(128, input_shape=input_shape, return_sequences=True))\n",
        "rnn_model.add(keras.layers.LSTM(64)) \n",
        "\n",
        "# dense layers\n",
        "rnn_model.add(keras.layers.Dense(64, activation='relu'))\n",
        "rnn_model.add(keras.layers.Dropout(0.3)) \n",
        "rnn_model.add(keras.layers.Dense(64, activation='relu'))\n",
        "rnn_model.add(keras.layers.Dropout(0.3)) \n",
        "\n",
        "# output layer\n",
        "rnn_model.add(keras.layers.Dense(13, activation='softmax'))\n",
        "\n",
        "# Compile Model\n",
        "rnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "history = rnn_model.fit(X_train, y_train, validation_data=(X_validation, y_validation), \\\n",
        "                    batch_size=50, epochs=100)\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = rnn_model.evaluate(X_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "155/155 [==============================] - 21s 134ms/step - loss: 2.3478 - accuracy: 0.2174 - val_loss: 2.0572 - val_accuracy: 0.3929\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 19s 122ms/step - loss: 1.9743 - accuracy: 0.3554 - val_loss: 1.7058 - val_accuracy: 0.4865\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 1.7462 - accuracy: 0.4297 - val_loss: 1.5398 - val_accuracy: 0.5104\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 1.5747 - accuracy: 0.4854 - val_loss: 1.3834 - val_accuracy: 0.5657\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 19s 122ms/step - loss: 1.4299 - accuracy: 0.5330 - val_loss: 1.3345 - val_accuracy: 0.5683\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 1.3111 - accuracy: 0.5729 - val_loss: 1.1684 - val_accuracy: 0.6263\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 1.1959 - accuracy: 0.6139 - val_loss: 1.1932 - val_accuracy: 0.6310\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 1.1483 - accuracy: 0.6429 - val_loss: 1.1244 - val_accuracy: 0.6413\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 1.0376 - accuracy: 0.6771 - val_loss: 1.0444 - val_accuracy: 0.6667\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.9280 - accuracy: 0.7131 - val_loss: 1.0198 - val_accuracy: 0.6837\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.8691 - accuracy: 0.7364 - val_loss: 0.9633 - val_accuracy: 0.7029\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.8185 - accuracy: 0.7426 - val_loss: 0.9932 - val_accuracy: 0.7127\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.7376 - accuracy: 0.7716 - val_loss: 0.9537 - val_accuracy: 0.7329\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.7070 - accuracy: 0.7838 - val_loss: 0.9683 - val_accuracy: 0.7112\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.6603 - accuracy: 0.7978 - val_loss: 0.9327 - val_accuracy: 0.7371\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.6241 - accuracy: 0.8146 - val_loss: 0.9378 - val_accuracy: 0.7329\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.5539 - accuracy: 0.8342 - val_loss: 0.9955 - val_accuracy: 0.7417\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.5645 - accuracy: 0.8375 - val_loss: 0.9584 - val_accuracy: 0.7495\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.4833 - accuracy: 0.8576 - val_loss: 0.9535 - val_accuracy: 0.7516\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.4614 - accuracy: 0.8641 - val_loss: 0.8754 - val_accuracy: 0.7583\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.4022 - accuracy: 0.8901 - val_loss: 0.9324 - val_accuracy: 0.7764\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.3946 - accuracy: 0.8900 - val_loss: 0.9260 - val_accuracy: 0.7769\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.3906 - accuracy: 0.8942 - val_loss: 0.9969 - val_accuracy: 0.7707\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.4105 - accuracy: 0.8859 - val_loss: 0.9590 - val_accuracy: 0.7676\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.3140 - accuracy: 0.9200 - val_loss: 0.9805 - val_accuracy: 0.7748\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.2998 - accuracy: 0.9232 - val_loss: 0.9259 - val_accuracy: 0.7867\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 19s 122ms/step - loss: 0.2911 - accuracy: 0.9278 - val_loss: 1.1069 - val_accuracy: 0.7562\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.2738 - accuracy: 0.9316 - val_loss: 1.0214 - val_accuracy: 0.7826\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.2482 - accuracy: 0.9406 - val_loss: 0.9059 - val_accuracy: 0.7924\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.2695 - accuracy: 0.9332 - val_loss: 0.9728 - val_accuracy: 0.7883\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1987 - accuracy: 0.9490 - val_loss: 0.9803 - val_accuracy: 0.7888\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 18s 119ms/step - loss: 0.2471 - accuracy: 0.9376 - val_loss: 0.9661 - val_accuracy: 0.7919\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 18s 119ms/step - loss: 0.2023 - accuracy: 0.9513 - val_loss: 0.9895 - val_accuracy: 0.8069\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.2051 - accuracy: 0.9504 - val_loss: 1.0227 - val_accuracy: 0.7821\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.2254 - accuracy: 0.9448 - val_loss: 0.9564 - val_accuracy: 0.7976\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.1967 - accuracy: 0.9474 - val_loss: 1.1054 - val_accuracy: 0.7842\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.1481 - accuracy: 0.9645 - val_loss: 1.0867 - val_accuracy: 0.7992\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.1726 - accuracy: 0.9593 - val_loss: 1.0634 - val_accuracy: 0.8043\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1446 - accuracy: 0.9654 - val_loss: 1.1408 - val_accuracy: 0.7981\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1796 - accuracy: 0.9537 - val_loss: 1.0297 - val_accuracy: 0.7955\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1317 - accuracy: 0.9702 - val_loss: 1.1707 - val_accuracy: 0.7945\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1316 - accuracy: 0.9691 - val_loss: 1.0762 - val_accuracy: 0.8028\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1327 - accuracy: 0.9687 - val_loss: 1.0832 - val_accuracy: 0.7971\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1412 - accuracy: 0.9675 - val_loss: 1.0415 - val_accuracy: 0.8188\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0997 - accuracy: 0.9763 - val_loss: 1.1376 - val_accuracy: 0.8163\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1697 - accuracy: 0.9593 - val_loss: 1.0130 - val_accuracy: 0.8090\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1125 - accuracy: 0.9745 - val_loss: 1.0689 - val_accuracy: 0.8137\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1049 - accuracy: 0.9764 - val_loss: 1.1026 - val_accuracy: 0.8100\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1357 - accuracy: 0.9694 - val_loss: 1.1123 - val_accuracy: 0.8106\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1128 - accuracy: 0.9723 - val_loss: 1.0554 - val_accuracy: 0.7971\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1437 - accuracy: 0.9663 - val_loss: 1.1026 - val_accuracy: 0.8126\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1091 - accuracy: 0.9733 - val_loss: 1.0818 - val_accuracy: 0.8126\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1009 - accuracy: 0.9767 - val_loss: 1.1527 - val_accuracy: 0.8147\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.1122 - accuracy: 0.9732 - val_loss: 1.0832 - val_accuracy: 0.7945\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.0993 - accuracy: 0.9792 - val_loss: 1.0047 - val_accuracy: 0.8157\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.0597 - accuracy: 0.9868 - val_loss: 1.1568 - val_accuracy: 0.8142\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.0475 - accuracy: 0.9882 - val_loss: 1.2342 - val_accuracy: 0.8188\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 18s 119ms/step - loss: 0.0816 - accuracy: 0.9814 - val_loss: 1.1762 - val_accuracy: 0.7878\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.0952 - accuracy: 0.9789 - val_loss: 1.1583 - val_accuracy: 0.7940\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1456 - accuracy: 0.9683 - val_loss: 0.9732 - val_accuracy: 0.8111\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0656 - accuracy: 0.9852 - val_loss: 1.1056 - val_accuracy: 0.8095\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0893 - accuracy: 0.9808 - val_loss: 1.2410 - val_accuracy: 0.7961\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1355 - accuracy: 0.9685 - val_loss: 1.0991 - val_accuracy: 0.8002\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0825 - accuracy: 0.9794 - val_loss: 1.1032 - val_accuracy: 0.8199\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0533 - accuracy: 0.9890 - val_loss: 1.2468 - val_accuracy: 0.8054\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0855 - accuracy: 0.9805 - val_loss: 1.1230 - val_accuracy: 0.8111\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0744 - accuracy: 0.9824 - val_loss: 1.1465 - val_accuracy: 0.8204\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0840 - accuracy: 0.9814 - val_loss: 1.1164 - val_accuracy: 0.8069\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0771 - accuracy: 0.9837 - val_loss: 1.1538 - val_accuracy: 0.8116\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0949 - accuracy: 0.9790 - val_loss: 1.1835 - val_accuracy: 0.7852\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0791 - accuracy: 0.9806 - val_loss: 1.1573 - val_accuracy: 0.8183\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.0841 - accuracy: 0.9814 - val_loss: 1.0755 - val_accuracy: 0.8064\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0787 - accuracy: 0.9816 - val_loss: 1.2750 - val_accuracy: 0.8033\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0962 - accuracy: 0.9794 - val_loss: 1.1845 - val_accuracy: 0.7940\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0888 - accuracy: 0.9803 - val_loss: 1.2817 - val_accuracy: 0.8038\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.0673 - accuracy: 0.9842 - val_loss: 1.1798 - val_accuracy: 0.8204\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 19s 122ms/step - loss: 0.0741 - accuracy: 0.9828 - val_loss: 1.0086 - val_accuracy: 0.8251\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.0449 - accuracy: 0.9905 - val_loss: 1.1225 - val_accuracy: 0.8287\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.0604 - accuracy: 0.9869 - val_loss: 1.0831 - val_accuracy: 0.8142\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 19s 122ms/step - loss: 0.0557 - accuracy: 0.9874 - val_loss: 1.1365 - val_accuracy: 0.8271\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 19s 122ms/step - loss: 0.0694 - accuracy: 0.9839 - val_loss: 1.2355 - val_accuracy: 0.8194\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1027 - accuracy: 0.9776 - val_loss: 1.0138 - val_accuracy: 0.8090\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.0512 - accuracy: 0.9891 - val_loss: 1.1217 - val_accuracy: 0.8297\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0890 - accuracy: 0.9779 - val_loss: 0.9694 - val_accuracy: 0.8323\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 18s 119ms/step - loss: 0.0577 - accuracy: 0.9863 - val_loss: 1.2173 - val_accuracy: 0.8080\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 19s 120ms/step - loss: 0.0642 - accuracy: 0.9832 - val_loss: 1.1292 - val_accuracy: 0.8256\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0433 - accuracy: 0.9882 - val_loss: 1.2535 - val_accuracy: 0.8230\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0596 - accuracy: 0.9877 - val_loss: 1.0961 - val_accuracy: 0.8292\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0582 - accuracy: 0.9878 - val_loss: 1.1432 - val_accuracy: 0.8287\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0625 - accuracy: 0.9852 - val_loss: 1.1275 - val_accuracy: 0.8142\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0555 - accuracy: 0.9876 - val_loss: 1.0516 - val_accuracy: 0.8328\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0736 - accuracy: 0.9849 - val_loss: 1.0158 - val_accuracy: 0.8240\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0448 - accuracy: 0.9896 - val_loss: 1.1354 - val_accuracy: 0.8240\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0357 - accuracy: 0.9922 - val_loss: 1.2053 - val_accuracy: 0.8276\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0318 - accuracy: 0.9925 - val_loss: 1.1333 - val_accuracy: 0.8458\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 1.2889 - val_accuracy: 0.8354\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0746 - accuracy: 0.9847 - val_loss: 1.2980 - val_accuracy: 0.8033\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.1054 - accuracy: 0.9785 - val_loss: 1.1172 - val_accuracy: 0.8209\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0664 - accuracy: 0.9839 - val_loss: 1.1002 - val_accuracy: 0.8359\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 19s 121ms/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 1.1212 - val_accuracy: 0.8421\n",
            "101/101 - 3s - loss: 1.1111 - accuracy: 0.8481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1Cs9kETVhYu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9da1a3e3-6bb0-413e-d9a1-4c1785e69f6c"
      },
      "source": [
        "rnn_model.save(f'{WORKING_FOLDER}/saved_models/rnn_model0')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Apollo's Ear/saved_models/rnn_model0/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5h1ODwNC6yK"
      },
      "source": [
        "# Results\n",
        "We have now successfully implemented 3 audio classification systems with different architectures. The MLP model has an accuracy of 79%, the CNN an accuracy of 78%, and the RNN_LSTM has the highest accuracy of 84%. \n",
        "We have exceeded our goal of 80% with the RNN_LSTM but fallen short with the other models. However it is only by 1 to 2 %.\n",
        "Overall, the exercise was very sucessful. Along the way we gained useful knowledge about audio characteristics and features extraction, Tensorflow, taking advantage of open-source resources, and for those who used Selenium, about browser automation."
      ]
    }
  ]
}